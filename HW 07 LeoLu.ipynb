{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605b4b8e",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad97447",
   "metadata": {},
   "source": [
    "#### 1\n",
    "Simple Linear Regression models the relationship between one predictor, which is: outcome=β0+β1 predictor\n",
    "\n",
    "But Multiple Linear Regression includes more than one predictor, which is: outcome=β0+β1predictor1+β2predictor2+......βkpredictork\n",
    "\n",
    "The benefit of Multiple Linear Regression is multiple predictors can explain more variance, showing complex relationships and interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b6c4d",
   "metadata": {},
   "source": [
    "#### 2\n",
    "Continuous variable represents a variable that can take a range of values, for example, height, age......Which can be written as outcome=β0+β1continuous variable\n",
    "\n",
    "Indicator variable represents binary states, for example, gender......Which can be written as outcome=β0+β1 1(indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7101ca",
   "metadata": {},
   "source": [
    "#### 3\n",
    "Adding indicator variables to create a multiple linear regression allows for different intercepts to be considered depending on the state of the indicator variables, effectively modeling separate lines for each grouping, but with the same slope.\n",
    "\n",
    "The model would be outcome=β0+β1continuous variable+β2 1(indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250adbd",
   "metadata": {},
   "source": [
    "#### 4\n",
    "The interaction term allows for different slopes for each group defined by the indicator. The continuous predictor's effect changes based on the indicator's state.\n",
    "\n",
    "Model: outcome=β0+β1continuous variable+β2 1(indicator)+β3(continuous * 1(indicator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112e07c",
   "metadata": {},
   "source": [
    "#### 5\n",
    "Encodes a categorical variable with K levels using K-1 indicator variables. One category (baseline) has an intercept of β0, and each other category shifts the intercept by βi\n",
    "\n",
    "Model: outcome = $\\beta_0$ + $\\beta_1$1(category1) + $\\beta_2$1(category2) + ......$\\beta_{k-1}$1(categoryk-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbff169",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf639dd",
   "metadata": {},
   "source": [
    "#### 1\n",
    "##### Outcome and Predictor Variables\n",
    "Outcome Variable (Y): Sales revenue or number of sales resulting from the advertising campaigns.\n",
    "Predictor Variables (X1 and X2):\n",
    "X1: Amount spent on TV advertising (continuous).\n",
    "X2: Amount spent on online advertising (continuous).\n",
    "##### Linear Forms\n",
    "Without Interaction: Y = $\\beta_0$ + $\\beta_1$X1 + $\\beta_2$X2 + ϵ\n",
    "\n",
    "This model assumes that the effects of TV and online advertising on sales are independent of each other. It estimates how much each dollar spent on TV or online contributes to sales, separately.\n",
    "\n",
    "With Interaction: Y = $\\beta_0$ + $\\beta_1$X1 + $\\beta_2$X2 + $\\beta_3$(X1 * X2) + ϵ\n",
    "\n",
    "This model includes the term $\\beta_3$(X1 * X2), which represents the interaction effect between TV and online advertising. It adjusts for scenarios where the effectiveness of one advertising type changes depending on the level of the other. Predictions here capture more nuanced relationships, possibly showing that combined advertising efforts have a multiplicative effect on sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42aeb3",
   "metadata": {},
   "source": [
    "#### 2\n",
    "suppose advertising budgets are either “high” or “low,” represented as binary variables:\n",
    "\n",
    "X1: High/Low TV advertising budget (coded as 1 for “high” and 0 for “low”).\n",
    "X2: High/Low online advertising budget (coded similarly).\n",
    "##### Linear Forms\n",
    "Without Interaction: Y = $\\beta_0$ + $\\beta_1$X1 + $\\beta_2$X2 + ϵ\n",
    "\n",
    "This model estimates how sales change when moving from a “low” to a “high” budget for TV or online, independently.\n",
    "\n",
    "With Interaction: Y = $\\beta_0$ + $\\beta_1$X1 + $\\beta_2$X2 + $\\beta_3$(X1 * X2) + ϵ\n",
    "\n",
    "$\\beta_3$(X1 * X2) captures how the combination of high/low budgets for both platforms affects sales. It allows for the model to show that having both budgets set to “high” might lead to a combined effect greater or lesser than the sum of their individual effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83be0a",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e3664",
   "metadata": {},
   "source": [
    "## There's a bug I haven't been able to fix, and neither has ChatGPT, so I have to skip over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41762515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CONNECTION_social_media_time_per_day'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CONNECTION_social_media_time_per_day'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m cscs_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m, skip_blank_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a binary outcome variable for logistic regression\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cscs_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_binary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[43mcscs_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCONNECTION_social_media_time_per_day\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2-3 hours per day\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Scale the continuous predictor variable to help with convergence\u001b[39;00m\n\u001b[1;32m     13\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CONNECTION_social_media_time_per_day'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset with updated error handling\n",
    "file_path = 'https://github.com/LeoLuLL/LeoLu-Sta130/blob/main/CSCS.csv'\n",
    "cscs_data = pd.read_csv(file_path, delimiter=',', on_bad_lines='skip', skip_blank_lines=True).fillna('')\n",
    "\n",
    "# Create a binary outcome variable for logistic regression\n",
    "cscs_data['social_media_binary'] = (cscs_data['CONNECTION_social_media_time_per_day'] == '2-3 hours per day').astype(int)\n",
    "\n",
    "# Scale the continuous predictor variable to help with convergence\n",
    "scaler = StandardScaler()\n",
    "cscs_data['DEMO_age_scaled'] = scaler.fit_transform(cscs_data[['DEMO_age']])\n",
    "\n",
    "# Fit the logistic regression model using the scaled continuous variable\n",
    "log_reg_fit = smf.logit('social_media_binary ~ DEMO_age_scaled', data=cscs_data).fit()\n",
    "\n",
    "# Display the summary of the logistic regression model\n",
    "print(log_reg_fit.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bce1f",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed46e7",
   "metadata": {},
   "source": [
    "### Breakdown of the Statements\n",
    "\n",
    "1. **\"The model only explains 17.6% of the variability in the data\"**:\n",
    "   - This refers to the \\( R^2 \\) value of the model. An \\( R^2 \\) of 17.6% means that only 17.6% of the total variability in the dependent variable (`HP` in this case) is explained by the model's predictors (`Sp. Def`, `Generation`, and their interaction).\n",
    "   - This is considered low, suggesting that other unmeasured factors contribute to the remaining 82.4% of the variability in `HP`.\n",
    "\n",
    "2. **\"Many of the coefficients are larger than 10 while having strong or very strong evidence against the null hypothesis of 'no effect'\"**:\n",
    "   - This indicates that some of the estimated coefficients in the model are statistically significant, meaning that their p-values are small (e.g., less than 0.05). A significant p-value provides evidence against the null hypothesis that these predictors have no effect on the outcome.\n",
    "   - Large coefficients (values greater than 10) suggest that the relationship between some of the predictors and `HP` is strong, at least in terms of the effect size.\n",
    "\n",
    "### Resolving the Contradiction\n",
    "\n",
    "- **Low \\( R^2 \\) vs. Significant Coefficients**: It's possible for a model to have significant coefficients even if the overall \\( R^2 \\) is low. This is because:\n",
    "  - **Statistical Significance**: Tests whether the predictors have a non-zero effect on the response variable, regardless of how much of the total variability they explain. It is influenced by the sample size and variability.\n",
    "  - **\\( R^2 \\)**: Measures how well the model as a whole explains the variability in the data. A low \\( R^2 \\) means the model does not explain much of the data's variation, but this doesn't mean the predictors have no effect. It suggests there might be other important variables not included in the model.\n",
    "\n",
    "### Why This Happens\n",
    "\n",
    "1. **Omitted Variables**: The model might lack important variables that significantly contribute to explaining `HP`, leading to a low \\( R^2 \\).\n",
    "2. **Strong Effects but Limited Scope**: The significant predictors might have strong individual effects but don't capture all relevant sources of variability in `HP`.\n",
    "3. **Interactions and Non-Linear Effects**: The relationships included (e.g., `Sp. Def` and `Generation` interaction) might only capture specific patterns rather than a comprehensive view of `HP`'s variability.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "A model can have significant coefficients yet explain a small portion of the total variability (low \\( R^2 \\)) if the predictors are meaningful but don't cover all factors affecting the response. In practice, this highlights that while the identified predictors have notable effects, the overall model's explanatory power is limited, suggesting a need for additional variables or a more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa47b5a",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f23b3a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>str8fyre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  str8fyre  \n",
       "370       55       65     70           3      False         0  \n",
       "6        109       85    100           1      False         1  \n",
       "242      105       75     45           2      False         0  \n",
       "661       70       85     50           5      False         0  \n",
       "288       20       30     20           3      False         0  \n",
       "..       ...      ...    ...         ...        ...       ...  \n",
       "522      130       95     65           4      False         0  \n",
       "243       65       45     75           2      False         0  \n",
       "797      150      130     70           6       True         0  \n",
       "117       60       45     35           1      False         0  \n",
       "409      120       90    120           3      False         0  \n",
       "\n",
       "[400 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca564d8c",
   "metadata": {},
   "source": [
    "Explanation: This cell prepares the pokeaman dataset for analysis. The data is split into training and testing sets using a 50/50 split. Any missing values in the \"Type 2\" column are replaced with \"None\" to ensure data consistency. A fixed random seed (130) is set to ensure reproducibility.\n",
    "\n",
    "Purpose: To create a baseline for model training and testing. It ensures that the data is clean and correctly partitioned before moving to model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5fdeedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:07:11</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     01:07:11     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        01:07:11   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9173269",
   "metadata": {},
   "source": [
    "Explanation: This cell defines a simple linear regression model where HP (the dependent variable) is predicted using Attack and Defense (independent variables). The model is then fitted using the training data, and a summary of the model is printed.\n",
    "\n",
    "Purpose: To evaluate the strength of Attack and Defense as predictors of HP. The summary includes important metrics such as the coefficients, p-values, and R-squared value, which indicate the goodness of fit and statistical significance of the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3301b5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model3)[0, 1]**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5089632",
   "metadata": {},
   "source": [
    "Explanation: The fitted model (model3_fit) is used to make predictions on the test set. The R-squared value for the training set (\"in sample\") is printed along with the R-squared value for the test set (\"out of sample\"), calculated using the correlation between actual and predicted HP values.\n",
    "\n",
    "Purpose: To compare the performance of the model on training data versus unseen data. This comparison helps illustrate how well the model generalizes and whether it is prone to overfitting (a high in-sample R-squared but a low out-of-sample R-squared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ae5f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:07:45</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Wed, 13 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     01:07:45     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        01:07:45   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f8425",
   "metadata": {},
   "source": [
    "Explanation: This cell constructs a more complex linear regression model (model4) that includes multiple predictors and interaction terms (e.g., Attack * Defense * Speed * Legendary). The Q() function is used to handle column names with special characters, like \"Sp. Def\" and \"Sp. Atk\".\n",
    "\n",
    "Purpose: To illustrate the effect of including interaction terms in a model. By adding interaction terms, the model attempts to capture more complex relationships between predictors and HP. The caution against including categorical predictors with many levels is to prevent the model from becoming computationally infeasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e1bfbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model4)[0, 1]**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a618f",
   "metadata": {},
   "source": [
    "Explanation: Similar to Cell 3, this cell evaluates the more complex model4 by making predictions on the test set and calculating both the in-sample and out-of-sample R-squared values.\n",
    "\n",
    "Purpose: To determine whether the more complex model improves predictive performance compared to the simpler model (model3). A better model should ideally have higher out-of-sample R-squared without significant overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910972a",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2f994",
   "metadata": {},
   "source": [
    "In the context of model4, the linear form specification (model4_linear_form) expands the predictor space by generating interaction terms and combinations between scaled and centered features, such as scale(center(Attack)) * scale(center(Defense)), along with other interactions including indicator variables like Legendary. This expanded set of predictors forms the design matrix model4_CS_spec.exog, which consists of columns representing these new interaction terms and scaled predictors.\n",
    "\n",
    "Multicollinearity arises when columns in the design matrix are highly correlated, meaning they don't provide unique, independent information. The correlation matrix (np.corrcoef(model4_spec.exog)) can reveal these dependencies. When multicollinearity is present, it inflates the condition number (Cond. No.), which indicates numerical instability and potential difficulties in estimating regression coefficients accurately.\n",
    "\n",
    "The high condition number seen in model4_CS_fit (even after centering and scaling) suggests severe multicollinearity, contributing to overfitting. This overfitting results in poor generalization for out-of-sample predictions, as the model learns noise and redundant information from the training data rather than meaningful relationships.\n",
    "\n",
    "In simpler terms, while centering and scaling help reduce multicollinearity to some extent, complex interactions involving many predictors and their correlations can still lead to models that perform poorly on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88329ec7",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373d8ef",
   "metadata": {},
   "source": [
    "To explain the development of the models concisely:\n",
    "\n",
    "#### Model 5 Development: \n",
    "The model (`model5_linear_form`) is constructed by incorporating main predictors such as `Attack`, `Defense`, `Speed`, `Sp. Def`, and `Sp. Atk`. It also adds categorical variables like `Generation`, `Type 1`, and `Type 2` to capture variability that may be influenced by these categories. This broad model aims to capture multiple contributing factors.\n",
    "\n",
    "\n",
    "#### Model 6 Development: \n",
    "The refinement in `model6_linear_form` involves selecting and retaining only the significant predictors from \n",
    "`model5_fit`. This includes continuous variables like `Attack`, `Speed`, `Sp. Def`, and `Sp. Atk`, as well as specific indicators such as \n",
    "certain `Type 1` categories (`Normal`, `Water`) and specific `Generations` (2, 5). This model is more focused, removing less influential\n",
    "terms to improve efficiency.\n",
    "\n",
    "\n",
    "#### Model 7 Development: \n",
    "`model7_linear_form` expands on `model6` by adding interaction terms among continuous variables (`Attack`, `Speed`, `Sp. Def`, and `Sp. Atk`) to capture combined effects that may be non-linear. The significant indicators from `model6` are retained. This adds complexity to better capture relationships among the variables.\n",
    "\n",
    "#### Centering and Scaling in Model 7:\n",
    "The final variation (`model7_linear_form_CS`) includes centered and scaled continuous variables, enhancing numerical stability (lowering the condition number). This reduces multicollinearity, which helps maintain prediction accuracy and interpretability in the presence of interactions.\n",
    "\n",
    "In summary, each model step involves refining predictors for significance, adding interaction terms for combined effects, and improving numerical stability by centering and scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbdb32",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14ffade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating a synthetic 'songs' dataset with relevant columns\n",
    "np.random.seed(42)\n",
    "songs = pd.DataFrame({\n",
    "    'danceability': np.random.rand(100),\n",
    "    'energy': np.random.rand(100),\n",
    "    'loudness': np.random.rand(100),\n",
    "    'mode': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "\n",
    "# Assuming `songs` is the dataset already loaded.\n",
    "linear_form = 'danceability ~ energy * loudness + energy * mode'\n",
    "\n",
    "reps = 100\n",
    "in_sample_Rsquared = np.zeros(reps)\n",
    "out_of_sample_Rsquared = np.zeros(reps)\n",
    "\n",
    "for i in range(reps):\n",
    "    # Random 50-50 train-test split without a fixed seed\n",
    "    songs_training_data, songs_testing_data = train_test_split(songs, train_size=0.5)\n",
    "    \n",
    "    # Fitting the model on the training data\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=songs_training_data).fit()\n",
    "    \n",
    "    # Recording in-sample R-squared\n",
    "    in_sample_Rsquared[i] = final_model_fit.rsquared\n",
    "    \n",
    "    # Predicting on the testing set and recording out-of-sample R-squared\n",
    "    predicted = final_model_fit.predict(songs_testing_data)\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(songs_testing_data.danceability, predicted)[0, 1] ** 2\n",
    "\n",
    "# Creating a DataFrame for visualization\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Plotting with Plotly\n",
    "fig = px.scatter(df, \n",
    "                 x=\"In Sample Performance (Rsquared)\", \n",
    "                 y=\"Out of Sample Performance (Rsquared)\", \n",
    "                 title=\"In Sample vs Out of Sample R-squared\")\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name=\"y=x\", line_shape='linear'))\n",
    "\n",
    "fig.show(renderer=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0ee1b",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb49304",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation:\n",
    "\n",
    "#### Models Overview\n",
    "`model7_fit`: A more complex linear regression model that includes higher-order interactions (e.g., a four-way interaction like `Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")`).\n",
    "`model6_fit`: A simpler linear regression model with fewer interactions and variables.\n",
    "\n",
    "#### Analysis Objective\n",
    "The goal is to assess which model is better for predicting future data, not just performing well on the training set. The idea is to avoid overfitting, where a model performs excellently on the training data but poorly on new, unseen data.\n",
    "\n",
    "#### Key Metrics Used\n",
    "R-squared (`rsquared`): Measures the proportion of variance in the dependent variable (HP) that is predictable from the independent variables.\n",
    "In-sample R-squared**: How well the model fits the training data.\n",
    "Out-of-sample R-squared**: How well the model generalizes to data not seen during training (testing data).\n",
    "\n",
    "#### Train-Test Splits\n",
    "The models are tested with subsets of data split by `Generation` (e.g., training on `Generation==1` and predicting on `Generation!=1`, and vice versa).\n",
    "This simulates a real-world scenario where models trained on current data predict outcomes for future data, highlighting potential generalizability issues.\n",
    "\n",
    "#### Key Insights\n",
    "Complexity vs. Generalizability: `model7_fit`, being more complex, tends to fit the training data well but might overfit due to its intricacy, especially evident in real-world testing where data arrives sequentially.\n",
    "Simpler Model Preference: `model6_fit`, although less complex, may generalize better due to its simplicity and more interpretable nature. This makes it potentially more reliable for predicting new data.\n",
    "Coefficient Evidence: The p-values from the summaries of these models indicate the strength of evidence for each coefficient. `model7_fit` might have weaker evidence for many of its coefficients compared to `model6_fit`, reinforcing the idea that complexity does not always equate to meaningful predictors.\n",
    "\n",
    "While `model7_fit` showed better predictive performance on an \"out-of-sample\" dataset during initial testing, its complexity makes it prone to overfitting. This means its performance could degrade in real-world settings where generalizability is crucial. In contrast, `model6_fit`, though simpler, provides a more robust and interpretable approach, balancing performance and the ability to generalize. This highlights the importance of considering model interpretability and simplicity, especially when predictive performance between models is similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb81f1",
   "metadata": {},
   "source": [
    "# Summary by ChatGPT\n",
    "#### 1\n",
    "The user requested explanations and corresponding equations for understanding two specific concepts in multiple linear regression:\n",
    "\n",
    "1. **Interaction Between a Continuous and an Indicator Variable**: The user wanted to know how including an interaction term between a continuous variable and an indicator (binary) variable affects a multiple linear regression model. I explained that this interaction term allows the effect of the continuous variable to vary depending on the level of the indicator variable and provided a linear form equation with interpretations for different cases.\n",
    "\n",
    "2. **Behavior of Models with Only Indicator Variables Derived from Non-Binary Categorical Variables**: The user asked for an explanation of how a multiple linear regression model behaves when it is based solely on indicator variables derived from a non-binary categorical variable. I described how such a model encodes the categories using \\(k-1\\) binary indicator variables (with one category as the reference) and provided an equation showing how the model expresses outcomes relative to the reference category.\n",
    "\n",
    "The conversation included detailed linear forms for both cases and interpretative explanations to help the user understand how these variables influence the model’s behavior.\n",
    "\n",
    "#### 2\n",
    "In this conversation, you requested guidance on logistic regression using a dataset from the Canadian Social Connection Survey. I examined the dataset and converted one of the categorical variables into a binary outcome to perform logistic regression. The logistic model was fitted with continuous and binary predictor variables, and its summary was provided, highlighting significant and non-significant predictors.\n",
    "\n",
    "I then explained how to interpret the logistic regression model's coefficients and how to use the model to make predictions. We attempted to visualize predicted probabilities using Plotly, but there were technical issues that prevented the plots from displaying.\n",
    "\n",
    "I provided the code and instructions to generate these visualizations in your own environment, ensuring you could explore how changes in predictors relate to predicted probabilities. If you need further assistance or a new visualization approach, please let me know!\n",
    "\n",
    "#### 3\n",
    "In this conversation, the user wanted to fit a logistic regression model using a dataset they provided from the Canadian Social Connection Survey. The initial goal was to create a binary outcome variable based on the `CONNECTION_social_media_time_per_day` column and use `DEMO_age` as a predictor. However, the code encountered multiple errors, including `ParserError`, `KeyError`, and issues related to column references.\n",
    "\n",
    "Key points covered:\n",
    "1. Initial code setup for loading the dataset and preparing it for logistic regression.\n",
    "2. Encountering errors such as `ParserError` due to bad data lines and handling them with `on_bad_lines='skip'`.\n",
    "3. Persistent `KeyError` issues related to the `CONNECTION_social_media_time_per_day` column, even though it was present in the data.\n",
    "4. Verification steps to check column names for hidden characters or formatting issues.\n",
    "5. Recommendations for re-running the process in a clean environment to prevent potential caching or context issues.\n",
    "\n",
    "The conversation involved iteratively debugging and refining the code to ensure that it worked correctly, including stripping whitespace from column names and handling non-numeric values in `DEMO_age`. The final code aimed to fit a logistic regression model using the `statsmodels` package with proper data handling and scaling.\n",
    "\n",
    "#### 4\n",
    "This conversation explores an apparent contradiction in interpreting results from a linear regression model. The user has modeled a dataset (using Pokémon data) with multiple predictors and interactions, observing that the model explains only 17.6% of the variability (low R-squared) but features coefficients that are large and statistically significant (strong evidence against the null hypothesis).\n",
    "\n",
    "The response explains that a model can have significant predictors with large coefficients while still having a low R-squared. This is possible when the predictors have an impact but do not collectively explain much of the variation in the dependent variable. It also discusses that low R-squared could be due to missing variables or complex relationships not captured by the model, emphasizing that significant predictors indicate their relevance but not necessarily a comprehensive explanatory power of the model.\n",
    "\n",
    "#### 5\n",
    "This conversation involved an explanation of five code cells related to fitting and evaluating linear regression models using the `pokeaman` dataset. \n",
    "\n",
    "1. **Data Preparation**: The first cell prepared the dataset by replacing missing values and splitting it into training and testing sets with a 50-50 split.\n",
    "2. **Model 3 Creation**: The second cell showed fitting a simple linear regression model (`HP ~ Attack + Defense`) and provided a summary of the model's performance metrics.\n",
    "3. **Model 3 Evaluation**: The third cell evaluated the model's in-sample and out-of-sample \\( R^2 \\) to assess its predictive ability on unseen data.\n",
    "4. **Model 4 Creation**: The fourth cell introduced a more complex model with multiple interaction terms and explained the potential computational issues with including too many interactions.\n",
    "5. **Model 4 Evaluation**: The fifth cell evaluated the complex model's predictive performance, calculating in-sample and out-of-sample \\( R^2 \\) to compare with the simpler model.\n",
    "\n",
    "The summary highlighted the workflow of preparing data, fitting simple and complex models, and assessing their performance to understand model generalization and complexity impacts.\n",
    "\n",
    "#### 6\n",
    "We discussed how the *design matrix* (`model4_spec.exog`) is formed in a linear regression model based on a specified linear form (`model4_linear_form_CS`), which includes main effects and interaction terms. This matrix is used to predict the outcome variable (`model4_spec.endog`). We examined the impact of **multicollinearity**—the high correlation between predictor variables in this design matrix—on the stability and performance of the model, particularly its **out-of-sample generalization**. \n",
    "\n",
    "High multicollinearity, indicated by an extremely large **condition number**, leads to unstable regression coefficients, making the model sensitive to small data changes and poor at predicting new data. While **centering and scaling** reduce multicollinearity and the condition number (e.g., in `model3_center_scale_fit`), this was insufficient for `model4_CS_fit` due to the complexity and correlations of interaction terms. This highlights the challenge of building reliable models with complex interactions and multicollinearity issues.\n",
    "\n",
    "#### 7\n",
    "You requested an explanation of how `model5_linear_form`, `model6_linear_form`, and `model7_linear_form` are extended and developed in the provided Python code. I outlined how:\n",
    "\n",
    "- **Model 5** includes a comprehensive set of predictors and categorical indicators to capture a broad range of potential influences on `HP`.\n",
    "- **Model 6** simplifies `model5` by retaining only significant predictors and introducing specific indicator variables, focusing on reducing overfitting and improving predictive power.\n",
    "- **Model 7** builds on `model6` by incorporating interaction terms among numeric predictors to reveal combined variable effects and deepen understanding.\n",
    "- A version of **Model 7 with centering and scaling** was discussed to handle multicollinearity issues, significantly improving model stability and interpretability.\n",
    "\n",
    "Overall, each model progressively refines and adds complexity to improve the prediction of `HP` while addressing potential issues like overfitting and multicollinearity.\n",
    "\n",
    "#### 8\n",
    "In this conversation, we discussed how to create a loop to iteratively split data, train a model, and capture \"in sample\" and \"out of sample\" R-squared metrics in a Python environment. I provided a detailed explanation of the purpose of this repeated sampling, focusing on evaluating model variability and potential overfitting. Additionally, I shared code for running this analysis, including importing necessary libraries, fitting the model, and visualizing results with Plotly.\n",
    "\n",
    "When a `NameError` occurred due to an undefined `songs` dataset, I suggested solutions to load or create a sample dataset. Finally, I explained how to save the resulting Plotly figure as a PNG file, including necessary setup steps for exporting the image using `kaleido`.\n",
    "\n",
    "#### 9\n",
    "This conversation focused on explaining a Python code snippet that evaluates the performance of two linear regression models, `model6` and `model7`, applied to Pokémon data. The models are trained on different subsets of data, specifically on Generation 1 or Generations 1 to 5 (excluding Generation 6). The analysis compares \"in-sample\" and \"out-of-sample\" R-squared values to assess how well these models fit the training data and predict on new data. The summary highlighted the importance of these metrics in understanding model overfitting and generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c06cb9",
   "metadata": {},
   "source": [
    "# History of ChatGPT\n",
    "1.https://chatgpt.com/share/67341066-c4fc-800b-b4f3-83fdc0b001ca\n",
    "\n",
    "2.https://chatgpt.com/share/673410a6-f400-800b-b1a7-e3bf6787ac75\n",
    "\n",
    "3.https://chatgpt.com/share/673410b2-bc40-800b-bbc6-9bc2380e084c\n",
    "\n",
    "4.https://chatgpt.com/share/673410d3-9e94-800b-ba8f-4f5047cb4138\n",
    "\n",
    "5.https://chatgpt.com/share/673410e2-5eec-800b-8287-e56f8b04e6f1\n",
    "\n",
    "6.https://chatgpt.com/share/673410ec-b15c-800b-9529-449426e55998\n",
    "\n",
    "7.https://chatgpt.com/share/673410f5-f228-800b-8896-b8d195c03264\n",
    "\n",
    "8.https://chatgpt.com/share/67341100-1f64-800b-81af-ea715a54091f\n",
    "\n",
    "9.https://chatgpt.com/share/67341109-e65c-800b-934c-9cae8cdb386e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edf76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
